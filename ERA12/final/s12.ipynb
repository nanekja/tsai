{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Albumentation library\n",
    "%pip install albumentations -qqq\n",
    "# Install GradCam\n",
    "%pip install grad-cam -qqq\n",
    "%pip install gradio -qqq\n",
    "%pip install pytorch-lightning -qqq\n",
    "%pip install torchmetrics -qqq\n",
    "%pip install torch-lr-finder -qqq\n",
    "\n",
    "# imports\n",
    "import os\n",
    "import torch, torchvision\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "torch.__version__, torchvision.__version__\n",
    "torch.cuda.is_available()\n",
    "import seaborn as sn  # for heatmaps\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "import sys\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR, OneCycleLR, ReduceLROnPlateau\n",
    "import torchmetrics\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from torchmetrics import Accuracy\n",
    "from torch_lr_finder import LRFinder\n",
    "import copy\n",
    "from torchvision.utils import make_grid, save_image\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningDataModule, LightningModule, Trainer\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelSummary\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATASETS = os.environ.get(\"PATH_DATASETS\", \".\")\n",
    "AVAIL_GPUS = min(1, torch.cuda.device_count())\n",
    "BATCH_SIZE = 256 if AVAIL_GPUS else 64\n",
    "AVAIL_GPUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "\n",
    "# Model\n",
    "class custom_ResNet(pl.LightningModule):\n",
    "    def __init__(self, data_dir=PATH_DATASETS):\n",
    "        super(custom_ResNet, self).__init__()\n",
    "\n",
    "      # Set our init args as class attributes\n",
    "      # Hardcode some dataset specific attributes\n",
    "        self.data_dir = data_dir\n",
    "        # self.learning_rate = learning_rate\n",
    "        self.classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "        self.num_classes = 10\n",
    "        self.train_transform = transforms.Compose([\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),  # Convert PIL image to tensor\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
    "        ])\n",
    "\n",
    "        self.test_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),  # Convert PIL image to tensor\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
    "        ])\n",
    "\n",
    "        # Define PyTorch model\n",
    "        # PREPARATION BLOCK\n",
    "        self.prepblock = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=(3, 3), padding=1, dilation=1, stride=1, bias=False),\n",
    "            nn.ReLU(),nn.BatchNorm2d(64))\n",
    "            # output_size = 32, RF=3\n",
    "\n",
    "\n",
    "        # CONVOLUTION BLOCK 1\n",
    "        self.convblock1_l1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3), padding=1, dilation=1, stride=1, bias=False),\n",
    "            # output_size = 32, RF=5\n",
    "            nn.MaxPool2d(2, 2),nn.ReLU(),nn.BatchNorm2d(128))\n",
    "            # output_size = 16, RF=6\n",
    "\n",
    "        self.convblock1_r1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3), padding=1, dilation=1, stride=1, bias=False),\n",
    "            nn.ReLU(),nn.BatchNorm2d(128),\n",
    "            # output_size = 16, RF=10\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3), padding=1, dilation=1, stride=1, bias=False),\n",
    "            nn.ReLU(),nn.BatchNorm2d(128))\n",
    "            # output_size = 16, RF=14\n",
    "\n",
    "\n",
    "        # CONVOLUTION BLOCK 2\n",
    "        self.convblock2_l1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(3, 3), padding=1, dilation=1, stride=1, bias=False),\n",
    "            # output_size = 16, RF=18\n",
    "            nn.MaxPool2d(2, 2),nn.ReLU(),nn.BatchNorm2d(256))\n",
    "            # output_size = 8, RF=20\n",
    "\n",
    "\n",
    "        # CONVOLUTION BLOCK 3\n",
    "        self.convblock3_l1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=(3, 3), padding=1, dilation=1, stride=1, bias=False),\n",
    "            # output_size = 8, RF=28\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.ReLU(),nn.BatchNorm2d(512))\n",
    "            # output_size = 4, RF=32\n",
    "\n",
    "\n",
    "        self.convblock3_r2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=(3, 3), padding=1, dilation=1, stride=1, bias=False),\n",
    "            nn.ReLU(),nn.BatchNorm2d(512),\n",
    "             # output_size = 4, RF=48\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=(3, 3), padding=1, dilation=1, stride=1, bias=False),\n",
    "            nn.ReLU(),nn.BatchNorm2d(512))\n",
    "            # output_size = 4, RF=64\n",
    "\n",
    "\n",
    "        # CONVOLUTION BLOCK 4\n",
    "        self.convblock4_mp = nn.Sequential(nn.MaxPool2d(4))\n",
    "        # output_size = 1, RF = 88\n",
    "\n",
    "\n",
    "        # OUTPUT BLOCK - Fully Connected layer\n",
    "        self.output_block = nn.Sequential(nn.Linear(in_features=512, out_features=10, bias=False))\n",
    "        # output_size = 1, RF = 88\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Preparation Block\n",
    "        x1 = self.prepblock(x)\n",
    "\n",
    "        # Convolution Block 1\n",
    "        x2 = self.convblock1_l1(x1)\n",
    "        x3 = self.convblock1_r1(x2)\n",
    "        x4 = x2 + x3\n",
    "\n",
    "        # Convolution Block 2\n",
    "        x5 = self.convblock2_l1(x4)\n",
    "\n",
    "        # Convolution Block 3\n",
    "        x6 = self.convblock3_l1(x5)\n",
    "        x7 = self.convblock3_r2(x6)\n",
    "        x8 = x7 + x6\n",
    "\n",
    "        # Convolution Block 4\n",
    "        x9 = self.convblock4_mp(x8)\n",
    "\n",
    "        # Output Block\n",
    "        x9 = x9.view(x9.size(0), -1)\n",
    "        x10 = self.output_block(x9)\n",
    "        return F.log_softmax(x10, dim=1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        pred = y_hat.argmax(dim=1, keepdim=True)\n",
    "        acc = pred.eq(y.view_as(pred)).float().mean()\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log('train_acc', acc, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        pred = y_hat.argmax(dim=1, keepdim=True)\n",
    "        acc = pred.eq(y.view_as(pred)).float().mean()\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        pred = y_hat.argmax(dim=1, keepdim=True)\n",
    "        acc = pred.eq(y.view_as(pred)).float().mean()\n",
    "        self.log('test_loss', loss, prog_bar=True)\n",
    "        self.log('test_acc', acc, prog_bar=True)\n",
    "        return pred\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        return optimizer\n",
    "\n",
    "\n",
    "    ####################\n",
    "    # DATA RELATED HOOKS\n",
    "    ####################\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # download\n",
    "        CIFAR10(self.data_dir, train=True, download=True)\n",
    "        CIFAR10(self.data_dir, train=False, download=True)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            cifar_full = CIFAR10(self.data_dir, train=True, download=True, transform=self.train_transform)\n",
    "            self.cifar_train, self.cifar_val = random_split(cifar_full, [45000, 5000])\n",
    "\n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "        if stage == \"test\" or stage is None:\n",
    "            self.cifar_test = CIFAR10(self.data_dir, train=False, download=True, transform=self.test_transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.cifar_train, batch_size=BATCH_SIZE, num_workers=os.cpu_count())\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.cifar_val, batch_size=BATCH_SIZE, num_workers=os.cpu_count())\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.cifar_test, batch_size=BATCH_SIZE, num_workers=os.cpu_count())\n",
    "\n",
    "    def collect_misclassified_images(self, num_images):\n",
    "        misclassified_images = []\n",
    "        misclassified_true_labels = []\n",
    "        misclassified_predicted_labels = []\n",
    "        num_collected = 0\n",
    "\n",
    "        for batch in self.test_dataloader():\n",
    "            x, y = batch\n",
    "            y_hat = self.forward(x)\n",
    "            pred = y_hat.argmax(dim=1, keepdim=True)\n",
    "            misclassified_mask = pred.eq(y.view_as(pred)).squeeze()\n",
    "            misclassified_images.extend(x[~misclassified_mask].detach())\n",
    "            misclassified_true_labels.extend(y[~misclassified_mask].detach())\n",
    "            misclassified_predicted_labels.extend(pred[~misclassified_mask].detach())\n",
    "\n",
    "            num_collected += sum(~misclassified_mask)\n",
    "\n",
    "            if num_collected >= num_images:\n",
    "                break\n",
    "\n",
    "        return misclassified_images[:num_images], misclassified_true_labels[:num_images], misclassified_predicted_labels[:num_images], len(misclassified_images)\n",
    "\n",
    "\n",
    "    def normalize_image(self, img_tensor):\n",
    "        min_val = img_tensor.min()\n",
    "        max_val = img_tensor.max()\n",
    "        return (img_tensor - min_val) / (max_val - min_val)\n",
    "\n",
    "    def get_gradcam_images(self, target_layer=-1, transparency=0.5, num_images=10):\n",
    "        misclassified_images, true_labels, predicted_labels, num_misclassified = self.collect_misclassified_images(num_images)\n",
    "        count = 0\n",
    "        k = 0\n",
    "        misclassified_images_converted = list()\n",
    "        gradcam_images = list()\n",
    "\n",
    "        if target_layer == -2:\n",
    "          target_layer = self.convblock2_l1.cpu()\n",
    "        else:\n",
    "          target_layer = self.convblock3_l1.cpu()\n",
    "\n",
    "        dataset_mean, dataset_std = np.array([0.49139968, 0.48215841, 0.44653091]), np.array([0.24703223, 0.24348513, 0.26158784])\n",
    "        grad_cam = GradCAM(model=self.cpu(), target_layers=target_layer, use_cuda=False)  # Move model to CPU\n",
    "\n",
    "        for i in range(0, num_images):\n",
    "            img_converted = misclassified_images[i].cpu().numpy().transpose(1, 2, 0)  # Convert tensor to numpy and transpose to (H, W, C)\n",
    "            img_converted = dataset_std * img_converted + dataset_mean\n",
    "            img_converted = np.clip(img_converted, 0, 1)\n",
    "            misclassified_images_converted.append(img_converted)\n",
    "            targets = [ClassifierOutputTarget(true_labels[i])]\n",
    "            grayscale_cam = grad_cam(input_tensor=misclassified_images[i].unsqueeze(0).cpu(), targets=targets)  # Move input to CPU\n",
    "            grayscale_cam = grayscale_cam[0, :]\n",
    "            output = show_cam_on_image(img_converted, grayscale_cam, use_rgb=True, image_weight=transparency)\n",
    "            gradcam_images.append(output)\n",
    "\n",
    "        return gradcam_images\n",
    "\n",
    "    def create_layout(self, num_images, use_gradcam):\n",
    "        num_cols = 3 if use_gradcam else 2\n",
    "        fig = plt.figure(figsize=(12, 5 * num_images))\n",
    "        gs = gridspec.GridSpec(num_images, num_cols, figure=fig, width_ratios=[0.3, 1, 1] if use_gradcam else [0.5, 1])\n",
    "\n",
    "        return fig, gs\n",
    "\n",
    "    def show_images_with_labels(self, fig, gs, i, img, label_text, use_gradcam=False, gradcam_img=None):\n",
    "        ax_img = fig.add_subplot(gs[i, 1])\n",
    "        ax_img.imshow(img)\n",
    "        ax_img.set_title(\"Original Image\")\n",
    "        ax_img.axis(\"off\")\n",
    "\n",
    "        if use_gradcam:\n",
    "            ax_gradcam = fig.add_subplot(gs[i, 2])\n",
    "            ax_gradcam.imshow(gradcam_img)\n",
    "            ax_gradcam.set_title(\"GradCAM Image\")\n",
    "            ax_gradcam.axis(\"off\")\n",
    "\n",
    "        ax_label = fig.add_subplot(gs[i, 0])\n",
    "        ax_label.text(0, 0.5, label_text, fontsize=10, verticalalignment='center')\n",
    "        ax_label.axis(\"off\")\n",
    "\n",
    "    def show_misclassified_images(self, num_images=10, use_gradcam=False, gradcam_layer=-1, transparency=0.5):\n",
    "        misclassified_images, true_labels, predicted_labels, num_misclassified = self.collect_misclassified_images(num_images)\n",
    "\n",
    "        fig, gs = self.create_layout(num_images, use_gradcam)\n",
    "\n",
    "        if use_gradcam:\n",
    "            grad_cam_images = self.get_gradcam_images(target_layer=gradcam_layer, transparency=transparency, num_images=num_images)\n",
    "\n",
    "        for i in range(num_images):\n",
    "            img = misclassified_images[i].numpy().transpose((1, 2, 0))  # Convert tensor to numpy and transpose to (H, W, C)\n",
    "            img = self.normalize_image(img)  # Normalize the image\n",
    "\n",
    "            # Show true label and predicted label on the left, and images on the right\n",
    "            label_text = f\"True Label: {self.classes[true_labels[i]]}\\nPredicted Label: {self.classes[predicted_labels[i]]}\"\n",
    "            self.show_images_with_labels(fig, gs, i, img, label_text, use_gradcam, grad_cam_images[i] if use_gradcam else None)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Lightning module\n",
    "model = custom_ResNet()\n",
    "\n",
    "# Tensorboard logger\n",
    "tb_logger = TensorBoardLogger(save_dir=\"logs/\", name=\"model\")\n",
    "\n",
    "# # Initialize the Lightning Trainer\n",
    "trainer = pl.Trainer(precision = 16, max_epochs=24, logger=tb_logger)\n",
    "trainer.fit(model)\n",
    "trainer.test()\n",
    "\n",
    "# show misclassified images\n",
    "plot = model.show_misclassified_images(num_images=10, use_gradcam=True, gradcam_layer=-2, transparency=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"custom_resnet_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start tensorboard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
